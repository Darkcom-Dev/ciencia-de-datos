{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 1-2 Introducción a Regresión Logística y Cross Validation\n",
    "\n",
    "## Regresión logística.\n",
    "\n",
    "La regresión logística es un algoritmo de clasificación utilizado para predecir la **probabilidad de que un evento ocurra**. A diferencia de la regresión lineal, que produce valores continuos, la regresión logística produce **valores entre 0 y 1**, que se interpretan como probabilidades. Se utiliza comúnmente en problemas de **clasificación binaria**, donde el resultado puede ser **verdadero/falso**, **sí/no**, etc. El algoritmo utiliza la función logística para modelar la relación entre las variables de entrada y la probabilidad del evento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.annual_inc.hist(bins=100, density=True)\n",
    "plt.title(\"Annual Income Distribution\")\n",
    "plt.xlabel(\"Annual Income\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='anual_income_dist_1.jpeg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(Data.annual_inc).hist(bins=100, density=True)\n",
    "plt.title(\"Annual Income Distribution\")\n",
    "plt.xlabel(\"Annual Income\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando logaritmo a los datos\n",
    "\n",
    "<img src='anual_income_dist_2.jpeg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "La validación cruzada (cross-validation) es una técnica utilizada para **evaluar el rendimiento de un modelo de aprendizaje automático**. Consiste en dividir el conjunto de datos en subconjuntos de entrenamiento y prueba de manera iterativa, de modo que cada subconjunto se utilice tanto para entrenar como para probar el modelo. Esto **permite obtener una evaluación más robusta del rendimiento del modelo** al promediar los resultados de múltiples particiones. La validación cruzada es **especialmente útil para evitar el sobreajuste (overfitting)** y para seleccionar hiperparámetros de manera más precisa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "for k, (train_index, test_index) in enumerate( skf.split(X, y) ):\n",
    "    plt.plot(train_index, [k+1 for _ in train_index], \".\")\n",
    "plt.ylim(0,6)\n",
    "plt.ylabel(\"FOLD\")\n",
    "plt.title(\"CROSS VALIDATION FOLDS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='cross_validation.jpeg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este fragmento de código define una función llamada \"compute_AUC\" que calcula el área bajo la curva ROC (AUC) para un modelo de regresión logística. Aquí está el desglose de lo que hace:\n",
    "\n",
    "Toma como entrada las características (X), las salidas (y) y los índices de división del conjunto de datos (train_index, test_index).\n",
    "Divide el conjunto de datos en conjuntos de entrenamiento y prueba utilizando los índices proporcionados.\n",
    "Ajusta un modelo de regresión logística a los datos de entrenamiento llamando a la función \"fit_logistic_regression\".\n",
    "Calcula las probabilidades predichas para las muestras de prueba utilizando el modelo ajustado, y extrae las probabilidades de pertenecer a la clase positiva.\n",
    "Calcula la tasa de falsos positivos (fpr), la tasa de verdaderos positivos (tpr) y el umbral (no utilizado) utilizando las etiquetas verdaderas y las probabilidades predichas.\n",
    "Calcula el área bajo la curva (AUC) utilizando las tasas de fpr y tpr.\n",
    "Devuelve el valor del AUC, así como las tasas de fpr y tpr.\n",
    "En resumen, esta función se encarga de calcular el AUC y las curvas ROC para un modelo de regresión logística en un conjunto de datos dado\n",
    "\n",
    "## Que es AUC y ROC\n",
    "\n",
    "El AUC (Area Under the Curve) es una métrica que se utiliza para evaluar la calidad de un modelo de clasificación binaria. Especifica la capacidad del modelo para discriminar entre las clases positiva y negativa. El AUC mide el área bajo la curva ROC (Receiver Operating Characteristic), que es un gráfico de la tasa de verdaderos positivos (eje y) frente a la tasa de falsos positivos (eje x) a varios umbrales de clasificación.\n",
    "\n",
    "En resumen, el AUC es una medida de la capacidad de discriminación de un modelo de clasificación binaria, y la curva ROC es una representación gráfica de esta capacidad. Un AUC más alto (más cercano a 1) indica un mejor rendimiento del modelo en la clasificación binaria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_AUC(X, y, train_index, test_index):\n",
    "    \"\"\"\n",
    "    feature/output: X, y\n",
    "    dataset split: train_index, test_index\n",
    "    \"\"\"\n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "\n",
    "    clf = fit_logistic_regression(X_train, y_train)\n",
    "    default_proba_test = clf.predict_proba(X_test)[:,1]  \n",
    "    fpr, tpr, _ = roc_curve(y_test, default_proba_test)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    return auc_score, fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_AUC(X,y, nfold=10):\n",
    "    \"\"\"\n",
    "    use a n-fold cross-validation for computing AUC estimates\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=nfold)  #create a cross-validation splitting\n",
    "    auc_list = [] #this list will contain the AUC estimates associated with each fold\n",
    "    for k, (train_index, test_index) in enumerate( skf.split(X, y) ):\n",
    "        auc_score, _, _ = compute_AUC(X, y, train_index, test_index)\n",
    "        auc_list.append(auc_score)\n",
    "    return auc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 5-6 Naive Bayes - Decision Tree - k-means\n",
    "\n",
    "> Nota: Openpyxl es una libreria que permite manipular archivos de Microsoft Excel: `from openpyxl import load_workbook # Needed to open XLSX files`\n",
    "> Nota2: La librería \"mglearn\" es una herramienta de visualización y utilidades para trabajar con algoritmos de aprendizaje automático en Python. Proporciona funciones y conjuntos de datos que son útiles para visualizar y comprender conceptos clave en aprendizaje automático, como regresión, clasificación, agrupación, selección de modelos y más. La librería \"mglearn\" es útil para educación, experimentación y visualización de resultados en aprendizaje automático. `! pip install mglearn;`\n",
    "\n",
    "\n",
    "El método consta de 3 pasos amplios, que se pueden resumir de la siguiente manera:\n",
    "\n",
    "1. Inicialización. Para comenzar, se deben seleccionar $k$ puntos (no necesariamente cualquiera de los puntos de datos, solo puntos en el mismo espacio dimensional) como los centroides \"iniciales\".\n",
    "2. Asignación. Cada punto de datos se asigna al grupo correspondiente al centroide más cercano a él (generalmente según la distancia euclidiana estándar).\n",
    "3. Actualización. Una vez que todos los puntos de datos se han asignado a sus respectivos grupos, se calcula un nuevo centroide para cada grupo tomando la media de todos los puntos de ese grupo.\n",
    "\n",
    "Luego se repiten los pasos 2 y 3 hasta que los grupos ya no cambien.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código implementa el algoritmo de k-means para la agrupación de datos. Aquí está el desglose de lo que hace:\n",
    "\n",
    "Se establece el número de clusters (k) en 4.\n",
    "Se inicializan las posiciones iniciales de los centroides de los clusters de forma aleatoria dentro de un rango específico.\n",
    "Se imprime la posición inicial de los centroides.\n",
    "Se define un mapeo de colores para visualizar los clusters.\n",
    "Se define una función llamada \"assignment\" que asigna cada punto de datos al centroide más cercano y asigna un color a cada punto basado en el centroide al que pertenece.\n",
    "Se aplica la función \"assignment\" a los datos normalizados y se muestra una vista previa de los datos asignados a los centroides.\n",
    "Se realiza una visualización de dispersión de los datos, con los puntos coloreados según su asignación a los centroides, y se muestran los centroides como puntos adicionales en el gráfico.\n",
    "En resumen, el código implementa el algoritmo de k-means para agrupar datos y visualiza los resultados de la agrupación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will begin our k-means method:\n",
    "\n",
    "# assign how many clusters (k-number) you would like to have\n",
    "k = 4\n",
    "\n",
    "# Initialization of cluster means \n",
    "centroids = {i+1: [np.random.choice([-1,-0.5,0.25,0.5]), np.random.choice([-1,-0.5,0.25,0.5])]\n",
    "    for i in range(k)\n",
    "}\n",
    "\n",
    "print(f\"Initial Centroids (age, income) are: {centroids}\")\n",
    "\n",
    "color_map = {1: 'r', 2: 'g', 3: 'b' , 4:'c', 5:'y'}\n",
    "\n",
    "def assignment(df, centroids):\n",
    "    tmp = df.copy()\n",
    "    for i in centroids.keys():\n",
    "        tmp[f\"distance_from_{i}\"] = (np.sqrt(\n",
    "            (df['income'] - centroids[i][0])*2 + (tmp['claims'] - centroids[i][1]) * 2)\n",
    "        ).round(2)\n",
    "        \n",
    "    centroid_distance_cols = [f\"distance_from_{i}\" for i in centroids.keys()]\n",
    "    \n",
    "    tmp['closest'] = tmp.loc[:, centroid_distance_cols].idxmin(axis=1)\n",
    "    tmp['closest'] = tmp['closest'].map(lambda x: int(x.lstrip('distance_from_')))\n",
    "    tmp['color'] = tmp['closest'].map(lambda x: color_map[x])\n",
    "    \n",
    "    return tmp\n",
    "\n",
    "df_centroids = assignment(df_norm, centroids)\n",
    "print(df_centroids.head())\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(df_centroids['income'], df_centroids['claims'], color=df_centroids['color'], alpha=0.5, edgecolor='k')\n",
    "\n",
    "for i in centroids.keys():\n",
    "    plt.scatter(*centroids[i], color=color_map[i])\n",
    "    \n",
    "plt.xlim(-1.5, 2.5)\n",
    "plt.xlabel('Income')\n",
    "\n",
    "plt.ylim(-1.5, 2.5)\n",
    "plt.ylabel('Claims')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este fragmento de código implementa la actualización de los centroides en el algoritmo de k-means. Aquí está el desglose de lo que hace:\n",
    "\n",
    "Se realiza una copia profunda de los centroides actuales para conservar los valores anteriores.\n",
    "Se define una función llamada \"update\" que calcula los nuevos centroides para cada cluster, tomando la media de las coordenadas de los puntos asignados a cada cluster.\n",
    "Se actualizan los centroides llamando a la función \"update\" y se almacenan los nuevos valores.\n",
    "Se realiza una visualización de dispersión de los datos, con los puntos coloreados según su asignación a los centroides, y se muestran los nuevos centroides como puntos adicionales en el gráfico. Además, se agregan flechas que muestran la dirección y magnitud del movimiento de los centroides desde su posición anterior hacia la nueva posición.\n",
    "En resumen, este código implementa el paso de actualización de los centroides en el algoritmo de k-means y visualiza el movimiento de los centroides en el espacio de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Step: In this step, we are taking updating the mean, by now calculating it based on\n",
    "# all the data points which were assigned to that k-th cluster.\n",
    "\n",
    "# Copy previous values and make a new entry called old_centroids. \n",
    "import copy\n",
    "\n",
    "old_centroids = copy.deepcopy(centroids)\n",
    "\n",
    "# Function to update the k-th clusters. \n",
    "def update(k):\n",
    "    for i in centroids.keys():\n",
    "        centroids[i][0] = np.mean(df_centroids[df_centroids['closest'] == i]['income'])\n",
    "        centroids[i][1] = np.mean(df_centroids[df_centroids['closest'] == i]['claims'])\n",
    "    return k\n",
    "\n",
    "centroids = update(centroids)\n",
    "    \n",
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.axes()\n",
    "\n",
    "plt.scatter(df_centroids['income'], df_centroids['claims'], color=df_centroids['color'], alpha=0.5, edgecolor='k')\n",
    "\n",
    "for i in centroids.keys():\n",
    "    plt.scatter(*centroids[i], color=color_map[i])\n",
    "    \n",
    "plt.xlim(-1.5, 2.5)\n",
    "plt.ylim(-1.5, 2.5)\n",
    "\n",
    "for i in old_centroids.keys():\n",
    "    old_x = old_centroids[i][0]\n",
    "    old_y = old_centroids[i][1]\n",
    "    \n",
    "    dx = (centroids[i][0] - old_centroids[i][0]) * 0.75\n",
    "    dy = (centroids[i][1] - old_centroids[i][1]) * 0.75\n",
    "    \n",
    "    ax.arrow(old_x, old_y, dx, dy, head_width=0.05, head_length=0.03, fc=color_map[i], ec=color_map[i])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este fragmento de código implementa la iteración del algoritmo de k-means hasta que no se realicen nuevas asignaciones de puntos a los centroides. Aquí está el desglose de lo que hace:\n",
    "\n",
    "Se realiza la asignación de los puntos a los centroides más cercanos llamando a la función \"assignment\" con los centroides actuales.\n",
    "Se inicia un bucle \"while True\" que continúa iterando hasta que no se realicen nuevas asignaciones de puntos a los centroides.\n",
    "En cada iteración del bucle, se realizan los siguientes pasos: a. Se guarda una copia de las asignaciones más recientes de puntos a los centroides. b. Se actualizan los centroides llamando a la función \"update\" con los centroides actuales. c. Se vuelve a realizar la asignación de puntos a los centroides llamando a la función \"assignment\" con los centroides actualizados. d. Se verifica si las asignaciones más recientes son iguales a las asignaciones anteriores. Si son iguales, se rompe el bucle y se detiene la iteración.\n",
    "Se realiza una visualización de dispersión de los datos, con los puntos coloreados según su asignación a los centroides, y se muestran los centroides actualizados como puntos adicionales en el gráfico.\n",
    "En resumen, este código implementa el bucle de iteración del algoritmo de k-means, que actualiza repetidamente las asignaciones de puntos a centroides y los centroides mismos hasta que no se realicen cambios en las asignaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative procedure: Reassign new weights \n",
    "df_centroids = assignment(df_centroids, centroids)\n",
    "\n",
    "# Continue doing this until no new assignments have been made \n",
    "while True:\n",
    "    closest_centroids = df_centroids['closest'].copy(deep=True)\n",
    "    centroids = update(centroids)\n",
    "    df_centroids = assignment(df_centroids, centroids)\n",
    "    \n",
    "    if closest_centroids.equals(df_centroids['closest']):\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(df_centroids['income'], df_centroids['claims'], color=df_centroids['color'], alpha=0.5, edgecolor='k')\n",
    "\n",
    "for i in centroids.keys():\n",
    "    plt.scatter(*centroids[i], color=color_map[i], edgecolor='k')\n",
    "    \n",
    "plt.xlim(-1.5, 2.5)\n",
    "plt.xlabel('Income [normalized]')\n",
    "\n",
    "plt.ylim(-1.5, 2.5)\n",
    "plt.ylabel('Claims [normalized]')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
